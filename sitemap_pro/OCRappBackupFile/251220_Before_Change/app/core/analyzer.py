"""
Analyzer Module
ã‚³ã‚¢åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ - ãƒ†ã‚­ã‚¹ãƒˆæ¯”è¼ƒã€é¡ä¼¼åº¦è¨ˆç®—ã€è‡ªå‹•ãƒãƒƒãƒãƒ³ã‚°
"""
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
from pathlib import Path
import difflib
import uuid


@dataclass
class DetectedArea:
    """
    æ¤œå‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢
    """
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    text: str = ""
    bbox: List[int] = field(default_factory=lambda: [0, 0, 0, 0])  # [x0, y0, x1, y1]
    confidence: float = 0.0
    source_type: str = ""  # "web" or "pdf"
    source_id: str = ""  # URL or PDF filename
    page_num: Optional[int] = None  # PDFã®å ´åˆã¯ãƒšãƒ¼ã‚¸ç•ªå·
    
    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "id": self.id,
            "text": self.text,
            "bbox": self.bbox,
            "confidence": self.confidence,
            "source_type": self.source_type,
            "source_id": self.source_id,
            "page_num": self.page_num
        }


@dataclass
class MatchedPair:
    """
    ãƒãƒƒãƒãƒ³ã‚°ã•ã‚ŒãŸWebã‚¨ãƒªã‚¢ã¨PDFã‚¨ãƒªã‚¢ã®ãƒšã‚¢
    """
    web_area: DetectedArea
    pdf_area: DetectedArea
    similarity_score: float
    match_type: str = "auto"  # "auto" or "manual"
    
    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "web_area": self.web_area.to_dict(),
            "pdf_area": self.pdf_area.to_dict(),
            "similarity_score": self.similarity_score,
            "match_type": self.match_type
        }


class ContentAnalyzer:
    """
    ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
    OCRçµæœã®ç®¡ç†ã€è‡ªå‹•ãƒãƒƒãƒãƒ³ã‚°ã€é¡ä¼¼åº¦è¨ˆç®—
    """
    
    def __init__(self, ocr_engine=None):
        """
        Args:
            ocr_engine: OCREngineã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.ocr_engine = ocr_engine
        self.web_areas: List[DetectedArea] = []
        self.pdf_areas: List[DetectedArea] = []
        self.matched_pairs: List[MatchedPair] = []
    
    def analyze_image(
        self,
        image_path: str,
        source_type: str,
        source_id: str,
        page_num: Optional[int] = None
    ) -> List[DetectedArea]:
        """
        ç”»åƒã‚’OCRã«ã‹ã‘ã€çµæœã‚’DetectedAreaã®ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦ä¿å­˜
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            source_type: "web" or "pdf"
            source_id: URL or PDF filename
            page_num: PDFã®å ´åˆã¯ãƒšãƒ¼ã‚¸ç•ªå·
        
        Returns:
            DetectedAreaã®ãƒªã‚¹ãƒˆ
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not Path(image_path).exists():
            print(f"âš ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
            return []
        
        # OCRã‚¨ãƒ³ã‚¸ãƒ³ã®ç¢ºèª
        if not self.ocr_engine:
            print("âš ï¸ OCRã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        try:
            # OCRå®Ÿè¡Œ
            print(f"ğŸ” OCRå®Ÿè¡Œä¸­: {Path(image_path).name}")
            result = self.ocr_engine.detect_document_text(image_path)
            
            if not result:
                print(f"âš ï¸ OCRçµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {image_path}")
                return []
            
            # DetectedAreaã«å¤‰æ›
            areas = []
            for block in result.get("blocks", []):
                area = DetectedArea(
                    text=block["text"],
                    bbox=block["bbox"],
                    confidence=block["confidence"],
                    source_type=source_type,
                    source_id=source_id,
                    page_num=page_num
                )
                areas.append(area)
            
            # ãƒªã‚¹ãƒˆã«è¿½åŠ 
            if source_type == "web":
                self.web_areas.extend(areas)
            elif source_type == "pdf":
                self.pdf_areas.extend(areas)
            
            print(f"âœ… {len(areas)} ã‚¨ãƒªã‚¢æ¤œå‡º: {Path(image_path).name}")
            return areas
            
        except Exception as e:
            print(f"âš ï¸ ç”»åƒåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def compute_auto_matches(
        self,
        threshold: float = 0.3,
        method: str = "hybrid"
    ) -> List[MatchedPair]:
        """
        Webã‚¨ãƒªã‚¢ã¨PDFã‚¨ãƒªã‚¢ã®ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã€è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°
        
        Args:
            threshold: ãƒãƒƒãƒãƒ³ã‚°é–¾å€¤
            method: é¡ä¼¼åº¦è¨ˆç®—æ–¹æ³• ("difflib", "jaccard", "hybrid")
        
        Returns:
            MatchedPairã®ãƒªã‚¹ãƒˆ
        """
        if not self.web_areas:
            print("âš ï¸ Webã‚¨ãƒªã‚¢ãŒã‚ã‚Šã¾ã›ã‚“")
            return []
        
        if not self.pdf_areas:
            print("âš ï¸ PDFã‚¨ãƒªã‚¢ãŒã‚ã‚Šã¾ã›ã‚“")
            return []
        
        print(f"ğŸ”„ è‡ªå‹•ãƒãƒƒãƒãƒ³ã‚°é–‹å§‹: Web {len(self.web_areas)} Ã— PDF {len(self.pdf_areas)}")
        
        self.matched_pairs.clear()
        
        try:
            # å„Webã‚¨ãƒªã‚¢ã«å¯¾ã—ã¦æœ€é©ãªPDFã‚¨ãƒªã‚¢ã‚’æ¢ã™
            for web_area in self.web_areas:
                best_match = None
                best_score = 0.0
                
                for pdf_area in self.pdf_areas:
                    # é¡ä¼¼åº¦ã‚’è¨ˆç®—
                    if method == "difflib":
                        score = self._calculate_similarity(web_area.text, pdf_area.text)
                    elif method == "jaccard":
                        score = self._calculate_jaccard(web_area.text, pdf_area.text)
                    else:  # hybrid
                        score1 = self._calculate_similarity(web_area.text, pdf_area.text)
                        score2 = self._calculate_jaccard(web_area.text, pdf_area.text)
                        score = (score1 + score2) / 2
                    
                    # æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²
                    if score > best_score:
                        best_score = score
                        best_match = pdf_area
                
                # é–¾å€¤ã‚’è¶…ãˆã¦ã„ã‚Œã°ãƒšã‚¢ã¨ã—ã¦è¿½åŠ 
                if best_match and best_score >= threshold:
                    pair = MatchedPair(
                        web_area=web_area,
                        pdf_area=best_match,
                        similarity_score=best_score,
                        match_type="auto"
                    )
                    self.matched_pairs.append(pair)
            
            print(f"âœ… {len(self.matched_pairs)} ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            return self.matched_pairs
            
        except Exception as e:
            print(f"âš ï¸ ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        difflib ã‚’ä½¿ç”¨ã—ãŸé¡ä¼¼åº¦è¨ˆç®—
        
        Args:
            text1: ãƒ†ã‚­ã‚¹ãƒˆ1
            text2: ãƒ†ã‚­ã‚¹ãƒˆ2
        
        Returns:
            é¡ä¼¼åº¦ (0.0-1.0)
        """
        if not text1 or not text2:
            return 0.0
        
        return difflib.SequenceMatcher(None, text1, text2).ratio()
    
    def _calculate_jaccard(self, text1: str, text2: str) -> float:
        """
        Jaccardä¿‚æ•°ã‚’è¨ˆç®—ï¼ˆå˜èªãƒ™ãƒ¼ã‚¹ï¼‰
        
        Args:
            text1: ãƒ†ã‚­ã‚¹ãƒˆ1
            text2: ãƒ†ã‚­ã‚¹ãƒˆ2
        
        Returns:
            Jaccardä¿‚æ•° (0.0-1.0)
        """
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return intersection / union if union > 0 else 0.0
    
    def find_differences(self, text1: str, text2: str) -> List[Dict]:
        """
        2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆé–“ã®å·®åˆ†ã‚’æ¤œå‡º
        
        Args:
            text1: ãƒ†ã‚­ã‚¹ãƒˆ1
            text2: ãƒ†ã‚­ã‚¹ãƒˆ2
        
        Returns:
            å·®åˆ†ãƒªã‚¹ãƒˆ [{"type": "add/delete/change", "text": str, "line": int}, ...]
        """
        differences = []
        
        # è¡Œã”ã¨ã«åˆ†å‰²
        lines1 = text1.splitlines()
        lines2 = text2.splitlines()
        
        # ndiff ã§å·®åˆ†ã‚’å–å¾—
        diff = difflib.ndiff(lines1, lines2)
        
        line_num = 0
        for item in diff:
            if item.startswith('+ '):  # è¿½åŠ 
                differences.append({
                    "type": "add",
                    "text": item[2:],
                    "line": line_num
                })
            elif item.startswith('- '):  # å‰Šé™¤
                differences.append({
                    "type": "delete",
                    "text": item[2:],
                    "line": line_num
                })
            elif item.startswith('? '):  # å¤‰æ›´ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿
                pass  # ã‚¹ã‚­ãƒƒãƒ—
            else:  # åŒä¸€è¡Œ
                line_num += 1
        
        return differences
    
    def add_manual_pair(
        self,
        web_area: DetectedArea,
        pdf_area: DetectedArea
    ) -> MatchedPair:
        """
        æ‰‹å‹•ã§ãƒšã‚¢ã‚’è¿½åŠ 
        
        Args:
            web_area: Webã‚¨ãƒªã‚¢
            pdf_area: PDFã‚¨ãƒªã‚¢
        
        Returns:
            ä½œæˆã•ã‚ŒãŸMatchedPair
        """
        # é¡ä¼¼åº¦ã‚’è¨ˆç®—
        score = self._calculate_similarity(web_area.text, pdf_area.text)
        
        pair = MatchedPair(
            web_area=web_area,
            pdf_area=pdf_area,
            similarity_score=score,
            match_type="manual"
        )
        
        self.matched_pairs.append(pair)
        print(f"âœ… æ‰‹å‹•ãƒšã‚¢è¿½åŠ : ã‚¹ã‚³ã‚¢ {score:.2%}")
        
        return pair
    
    def clear_all(self):
        """å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
        self.web_areas.clear()
        self.pdf_areas.clear()
        self.matched_pairs.clear()
        print("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
    
    def get_statistics(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return {
            "web_areas_count": len(self.web_areas),
            "pdf_areas_count": len(self.pdf_areas),
            "matched_pairs_count": len(self.matched_pairs),
            "average_similarity": sum(p.similarity_score for p in self.matched_pairs) / len(self.matched_pairs) if self.matched_pairs else 0.0
        }

