"""
Analyzer & OCREngine ã®å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Google Cloud Vision APIã®èªè¨¼æƒ…å ±ãªã—ã§ã‚‚å‹•ä½œã™ã‚‹åŸºæœ¬ãƒ†ã‚¹ãƒˆ
"""
import sys
import io
from pathlib import Path

# Windows UTF-8å¯¾å¿œ
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.core.analyzer import ContentAnalyzer, DetectedArea, MatchedPair


def test_basic_classes():
    """åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("ğŸ“ ãƒ†ã‚¹ãƒˆ1: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹")
    print("=" * 60)
    
    # DetectedArea ã®ä½œæˆ
    area = DetectedArea(
        text="ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ",
        bbox=[100, 100, 500, 200],
        confidence=0.95,
        source_type="web",
        source_id="https://example.com"
    )
    
    print(f"\nâœ… DetectedArea ä½œæˆæˆåŠŸ")
    print(f"   ID: {area.id}")
    print(f"   ãƒ†ã‚­ã‚¹ãƒˆ: {area.text}")
    print(f"   åº§æ¨™: {area.bbox}")
    print(f"   ä¿¡é ¼åº¦: {area.confidence}")
    
    # è¾æ›¸å¤‰æ›
    area_dict = area.to_dict()
    print(f"\nâœ… è¾æ›¸å¤‰æ›æˆåŠŸ")
    print(f"   ã‚­ãƒ¼æ•°: {len(area_dict)}")


def test_similarity_calculation():
    """é¡ä¼¼åº¦è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ” ãƒ†ã‚¹ãƒˆ2: é¡ä¼¼åº¦è¨ˆç®—")
    print("=" * 60)
    
    analyzer = ContentAnalyzer()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: å®Œå…¨ä¸€è‡´
    text1 = "ã“ã‚Œã¯åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã§ã™"
    text2 = "ã“ã‚Œã¯åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã§ã™"
    score = analyzer._calculate_similarity(text1, text2)
    print(f"\nâœ… å®Œå…¨ä¸€è‡´:")
    print(f"   é¡ä¼¼åº¦: {score:.2%}")
    assert score == 1.0, "å®Œå…¨ä¸€è‡´ã¯100%ã§ã‚ã‚‹ã¹ã"
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: éƒ¨åˆ†ä¸€è‡´
    text1 = "ã“ã‚Œã¯æœ€åˆã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™"
    text2 = "ã“ã‚Œã¯2ç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™"
    score = analyzer._calculate_similarity(text1, text2)
    print(f"\nâœ… éƒ¨åˆ†ä¸€è‡´:")
    print(f"   é¡ä¼¼åº¦: {score:.2%}")
    assert 0 < score < 1, "éƒ¨åˆ†ä¸€è‡´ã¯0%ã¨100%ã®é–“ã§ã‚ã‚‹ã¹ã"
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹3: Jaccardä¿‚æ•°
    text1 = "æ±äº¬ å¤§é˜ª äº¬éƒ½"
    text2 = "æ±äº¬ åå¤å±‹ ç¦å²¡"
    score = analyzer._calculate_jaccard(text1, text2)
    print(f"\nâœ… Jaccardä¿‚æ•°:")
    print(f"   é¡ä¼¼åº¦: {score:.2%}")


def test_difference_detection():
    """å·®åˆ†æ¤œå‡ºã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ ãƒ†ã‚¹ãƒˆ3: å·®åˆ†æ¤œå‡º")
    print("=" * 60)
    
    analyzer = ContentAnalyzer()
    
    text1 = """1è¡Œç›®ã®ãƒ†ã‚­ã‚¹ãƒˆ
2è¡Œç›®ã®ãƒ†ã‚­ã‚¹ãƒˆ
3è¡Œç›®ã®ãƒ†ã‚­ã‚¹ãƒˆ"""
    
    text2 = """1è¡Œç›®ã®ãƒ†ã‚­ã‚¹ãƒˆ
2è¡Œç›®ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ
4è¡Œç›®ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ"""
    
    differences = analyzer.find_differences(text1, text2)
    
    print(f"\nâœ… å·®åˆ†æ¤œå‡ºå®Œäº†: {len(differences)}ä»¶")
    for i, diff in enumerate(differences, 1):
        symbol = "+" if diff["type"] == "add" else "-" if diff["type"] == "delete" else "~"
        print(f"   {i}. [{symbol}] {diff['text']}")


def test_manual_pairing():
    """æ‰‹å‹•ãƒšã‚¢ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ–ï¸ ãƒ†ã‚¹ãƒˆ4: æ‰‹å‹•ãƒšã‚¢ãƒªãƒ³ã‚°")
    print("=" * 60)
    
    analyzer = ContentAnalyzer()
    
    # Webã‚¨ãƒªã‚¢ã‚’ä½œæˆ
    web_area = DetectedArea(
        text="ã‚µãƒ³ãƒ—ãƒ«Webãƒ†ã‚­ã‚¹ãƒˆ",
        bbox=[100, 100, 500, 200],
        confidence=0.95,
        source_type="web",
        source_id="https://example.com"
    )
    
    # PDFã‚¨ãƒªã‚¢ã‚’ä½œæˆ
    pdf_area = DetectedArea(
        text="ã‚µãƒ³ãƒ—ãƒ«PDFãƒ†ã‚­ã‚¹ãƒˆ",
        bbox=[110, 110, 510, 210],
        confidence=0.92,
        source_type="pdf",
        source_id="document.pdf",
        page_num=1
    )
    
    # ãƒšã‚¢ãƒªãƒ³ã‚°
    pair = analyzer.add_manual_pair(web_area, pdf_area)
    
    print(f"\nâœ… ãƒšã‚¢ãƒªãƒ³ã‚°å®Œäº†")
    print(f"   é¡ä¼¼åº¦: {pair.similarity_score:.2%}")
    print(f"   ã‚¿ã‚¤ãƒ—: {pair.match_type}")
    
    # çµ±è¨ˆæƒ…å ±
    stats = analyzer.get_statistics()
    print(f"\nğŸ“Š çµ±è¨ˆæƒ…å ±:")
    for key, value in stats.items():
        if isinstance(value, float):
            print(f"   {key}: {value:.2%}")
        else:
            print(f"   {key}: {value}")


def test_auto_matching():
    """è‡ªå‹•ãƒãƒƒãƒãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ¤– ãƒ†ã‚¹ãƒˆ5: è‡ªå‹•ãƒãƒƒãƒãƒ³ã‚°")
    print("=" * 60)
    
    analyzer = ContentAnalyzer()
    
    # è¤‡æ•°ã®Webã‚¨ãƒªã‚¢ã‚’è¿½åŠ 
    web_texts = [
        "æ±äº¬éƒ½æ¸‹è°·åŒºã®ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³æƒ…å ±",
        "å¤§é˜ªåºœå¤§é˜ªå¸‚ã®è¦³å…‰ã‚¹ãƒãƒƒãƒˆ",
        "äº¬éƒ½åºœäº¬éƒ½å¸‚ã®å¯ºç¤¾ä»é–£"
    ]
    
    for i, text in enumerate(web_texts):
        area = DetectedArea(
            text=text,
            bbox=[100, 100 + i*100, 500, 200 + i*100],
            confidence=0.9,
            source_type="web",
            source_id=f"https://example.com/page{i+1}"
        )
        analyzer.web_areas.append(area)
    
    # è¤‡æ•°ã®PDFã‚¨ãƒªã‚¢ã‚’è¿½åŠ 
    pdf_texts = [
        "æ±äº¬éƒ½æ¸‹è°·åŒºã®é£²é£Ÿåº—æƒ…å ±",
        "åå¤å±‹å¸‚ã®è¦³å…‰æƒ…å ±",
        "äº¬éƒ½å¸‚å†…ã®ç¥ç¤¾ã¨ãŠå¯º"
    ]
    
    for i, text in enumerate(pdf_texts):
        area = DetectedArea(
            text=text,
            bbox=[100, 100 + i*100, 500, 200 + i*100],
            confidence=0.88,
            source_type="pdf",
            source_id="document.pdf",
            page_num=i+1
        )
        analyzer.pdf_areas.append(area)
    
    # è‡ªå‹•ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
    pairs = analyzer.compute_auto_matches(threshold=0.3, method="hybrid")
    
    print(f"\nâœ… ãƒãƒƒãƒãƒ³ã‚°å®Œäº†: {len(pairs)} ãƒšã‚¢")
    
    for i, pair in enumerate(pairs, 1):
        print(f"\n   ãƒšã‚¢ {i}:")
        print(f"     Web: {pair.web_area.text}")
        print(f"     PDF: {pair.pdf_area.text}")
        print(f"     é¡ä¼¼åº¦: {pair.similarity_score:.2%}")


def run_all_tests():
    """å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("\nğŸš€ ContentAnalyzer å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    try:
        test_basic_classes()
        test_similarity_calculation()
        test_difference_detection()
        test_manual_pairing()
        test_auto_matching()
        
        print("\n" + "=" * 60)
        print("âœ… å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("=" * 60)
        
    except AssertionError as e:
        print(f"\nâŒ ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return False
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

