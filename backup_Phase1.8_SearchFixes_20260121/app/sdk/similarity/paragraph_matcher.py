"""
MEKIKI SDK - Paragraph Matcher
Web/PDFãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

æ©Ÿèƒ½:
- Webé¸æŠã¨PDFé¸æŠã®æœ€é©ãƒãƒƒãƒãƒ³ã‚°
- ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ã«ã‚ˆã‚‹è‡ªå‹•ãƒšã‚¢ãƒªãƒ³ã‚°
- è²ªæ¬²æ³•ã«ã‚ˆã‚‹é«˜é€Ÿãƒãƒƒãƒãƒ³ã‚°

ä½¿ç”¨ä¾‹:
    from app.sdk.similarity.paragraph_matcher import ParagraphMatcher
    
    matcher = ParagraphMatcher(threshold=0.25)
    sync_pairs = matcher.match(web_regions, pdf_regions)
"""

import logging
import difflib
from typing import List, Any, Optional
from dataclasses import dataclass

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


@dataclass
class SyncPair:
    """ãƒãƒƒãƒãƒ³ã‚°ãƒšã‚¢"""
    web_id: str
    pdf_id: str
    web_text: str
    pdf_text: str
    similarity: float
    web_bbox: Optional[tuple] = None
    pdf_bbox: Optional[tuple] = None


class ParagraphMatcher:
    """
    Web/PDFãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ãƒãƒƒãƒãƒ³ã‚° SDK
    
    â˜… æ©Ÿèƒ½:
    - å…¨çµ„ã¿åˆã‚ã›ã®é¡ä¼¼åº¦è¨ˆç®—
    - è²ªæ¬²æ³•ã«ã‚ˆã‚‹æœ€é©ãƒãƒƒãƒãƒ³ã‚°
    - é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    
    â˜… ãƒ­ã‚°å‡ºåŠ›:
    - ãƒãƒƒãƒãƒ³ã‚°é–‹å§‹/å®Œäº†
    - é¡ä¼¼åº¦è¡Œåˆ—ã‚µã‚¤ã‚º
    - ãƒãƒƒãƒãƒšã‚¢æ•°
    """
    
    def __init__(self, threshold: float = 0.25):
        """
        Args:
            threshold: ãƒãƒƒãƒãƒ³ã‚°é–¾å€¤ (0.0-1.0)
        """
        self.threshold = threshold
        logger.info(f"ParagraphMatcher initialized (threshold={threshold})")
    
    def match(
        self, 
        web_regions: List[Any], 
        pdf_regions: List[Any]
    ) -> List[SyncPair]:
        """
        Web/PDFé ˜åŸŸã‚’ãƒãƒƒãƒãƒ³ã‚°
        
        Args:
            web_regions: Webå´ã®é¸æŠé ˜åŸŸãƒªã‚¹ãƒˆ
            pdf_regions: PDFå´ã®é¸æŠé ˜åŸŸãƒªã‚¹ãƒˆ
        
        Returns:
            SyncPairã®ãƒªã‚¹ãƒˆ
        """
        print(f"\n{'='*50}")
        print(f"ğŸ”— ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ãƒãƒƒãƒãƒ³ã‚°é–‹å§‹")
        print(f"  Web: {len(web_regions)}ä»¶, PDF: {len(pdf_regions)}ä»¶")
        print(f"{'='*50}")
        
        if not web_regions or not pdf_regions:
            print("âš ï¸ ãƒãƒƒãƒãƒ³ã‚°: å…¥åŠ›ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return []
        
        # Step 1: é¡ä¼¼åº¦è¡Œåˆ—ã‚’è¨ˆç®—
        similarity_matrix = self._compute_similarity_matrix(web_regions, pdf_regions)
        
        # Step 2: è²ªæ¬²æ³•ã§æœ€é©ãƒãƒƒãƒã‚’é¸æŠ
        matches = self._greedy_match(web_regions, pdf_regions, similarity_matrix)
        
        print(f"\nâœ… ãƒãƒƒãƒãƒ³ã‚°å®Œäº†: {len(matches)}ãƒšã‚¢ç”Ÿæˆ")
        return matches
    
    def _compute_similarity_matrix(
        self, 
        web_regions: List[Any], 
        pdf_regions: List[Any]
    ) -> List[List[float]]:
        """å…¨çµ„ã¿åˆã‚ã›ã®é¡ä¼¼åº¦è¡Œåˆ—ã‚’è¨ˆç®—"""
        print(f"ğŸ“Š é¡ä¼¼åº¦è¡Œåˆ—è¨ˆç®—: {len(web_regions)} x {len(pdf_regions)}")
        
        matrix = []
        for i, web in enumerate(web_regions):
            row = []
            web_text = self._get_text(web)
            
            for j, pdf in enumerate(pdf_regions):
                pdf_text = self._get_text(pdf)
                score = self._calculate_similarity(web_text, pdf_text)
                row.append(score)
            
            matrix.append(row)
            
            # é€²æ—è¡¨ç¤º
            if (i + 1) % 5 == 0 or i == len(web_regions) - 1:
                print(f"  é€²æ—: {i+1}/{len(web_regions)}")
        
        return matrix
    
    def _greedy_match(
        self,
        web_regions: List[Any],
        pdf_regions: List[Any],
        similarity_matrix: List[List[float]]
    ) -> List[SyncPair]:
        """è²ªæ¬²æ³•ã§æœ€é©ãƒãƒƒãƒã‚’é¸æŠ"""
        print(f"ğŸ¯ è²ªæ¬²æ³•ãƒãƒƒãƒãƒ³ã‚° (é–¾å€¤: {self.threshold})")
        
        matches = []
        used_web = set()
        used_pdf = set()
        
        # å…¨ãƒšã‚¢ã‚’ã‚¹ã‚³ã‚¢é™é †ã§ã‚½ãƒ¼ãƒˆ
        all_pairs = []
        for i in range(len(web_regions)):
            for j in range(len(pdf_regions)):
                score = similarity_matrix[i][j]
                if score >= self.threshold:
                    all_pairs.append((score, i, j))
        
        all_pairs.sort(reverse=True, key=lambda x: x[0])
        
        # è²ªæ¬²ã«é¸æŠ
        for score, web_idx, pdf_idx in all_pairs:
            if web_idx in used_web or pdf_idx in used_pdf:
                continue
            
            web = web_regions[web_idx]
            pdf = pdf_regions[pdf_idx]
            
            pair = SyncPair(
                web_id=self._get_id(web),
                pdf_id=self._get_id(pdf),
                web_text=self._get_text(web),
                pdf_text=self._get_text(pdf),
                similarity=score,
                web_bbox=self._get_bbox(web),
                pdf_bbox=self._get_bbox(pdf)
            )
            matches.append(pair)
            used_web.add(web_idx)
            used_pdf.add(pdf_idx)
            
            print(f"  âœ“ {pair.web_id} â†” {pair.pdf_id}: {score:.1%}")
        
        # ãƒãƒƒãƒã—ãªã‹ã£ãŸé ˜åŸŸã‚‚è¿½åŠ  (score=0)
        for i, web in enumerate(web_regions):
            if i not in used_web:
                pair = SyncPair(
                    web_id=self._get_id(web),
                    pdf_id="",
                    web_text=self._get_text(web),
                    pdf_text="",
                    similarity=0.0,
                    web_bbox=self._get_bbox(web),
                    pdf_bbox=None
                )
                matches.append(pair)
        
        for j, pdf in enumerate(pdf_regions):
            if j not in used_pdf:
                pair = SyncPair(
                    web_id="",
                    pdf_id=self._get_id(pdf),
                    web_text="",
                    pdf_text=self._get_text(pdf),
                    similarity=0.0,
                    web_bbox=None,
                    pdf_bbox=self._get_bbox(pdf)
                )
                matches.append(pair)
        
        return matches
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ã‚’è¨ˆç®— (difflib SequenceMatcher)"""
        if not text1 or not text2:
            return 0.0
        
        # æ­£è¦åŒ–
        t1 = text1.strip().lower()
        t2 = text2.strip().lower()
        
        # SequenceMatcherã§è¨ˆç®—
        matcher = difflib.SequenceMatcher(None, t1, t2)
        return matcher.ratio()
    
    def _get_text(self, region: Any) -> str:
        """é ˜åŸŸã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        if hasattr(region, 'text'):
            return region.text or ""
        return str(region)
    
    def _get_id(self, region: Any) -> str:
        """é ˜åŸŸã‹ã‚‰IDã‚’å–å¾—"""
        if hasattr(region, 'area_code'):
            return region.area_code or ""
        if hasattr(region, 'id'):
            return str(region.id)
        return ""
    
    def _get_bbox(self, region: Any) -> Optional[tuple]:
        """é ˜åŸŸã‹ã‚‰åº§æ¨™ã‚’å–å¾—"""
        if hasattr(region, 'rect'):
            return region.rect
        if hasattr(region, 'bbox'):
            return region.bbox
        return None
    
    def set_threshold(self, threshold: float):
        """é–¾å€¤ã‚’è¨­å®š"""
        self.threshold = threshold
        logger.info(f"Threshold updated to {threshold}")
    
    def __repr__(self):
        return f"ParagraphMatcher(threshold={self.threshold})"


# ========== Convenience exports ==========
__all__ = ["ParagraphMatcher", "SyncPair"]
