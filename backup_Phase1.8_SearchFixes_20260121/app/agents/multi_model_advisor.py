"""
Multi-Model Advisor
Claude Opus 4 ã‚’ä¸»ä½“ã¨ã—ã€Gemini ã®æ„è¦‹ã‚‚å‚è€ƒè¡¨ç¤º

é‹ç”¨:
1. Claude (ä¸»ä½“): åˆ†æãƒ»è¨ˆç”»ãƒ»å®Ÿè£…æ¡ˆ
2. Gemini (å‚è€ƒ): ä»£æ›¿æ¡ˆãƒ»ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦–ç‚¹
3. ãƒ¦ãƒ¼ã‚¶ãƒ¼: æœ€çµ‚é¸æŠ
"""
import os
from typing import Optional, Dict
from dataclasses import dataclass


@dataclass
class Opinion:
    """ãƒ¢ãƒ‡ãƒ«ã®æ„è¦‹"""
    model: str
    role: str  # "primary" or "reference"
    content: str
    reasoning: str


class MultiModelAdvisor:
    """
    ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼
    
    Claude Opus 4 ã‚’ä¸»ä½“ã¨ã—ã¦ã€Gemini ã®æ„è¦‹ã‚‚å–å¾—ã—æ¯”è¼ƒè¡¨ç¤º
    """
    
    def __init__(self):
        self._claude_client = None
        self._gemini_client = None
        
        # Gemini API ã‚­ãƒ¼ (Google AI Studio)
        self.gemini_api_key = os.environ.get("GEMINI_API_KEY")
    
    def _init_claude(self):
        """Claude ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–"""
        if self._claude_client:
            return self._claude_client
        
        import anthropic
        self._claude_client = anthropic.Anthropic()
        return self._claude_client
    
    def _init_gemini(self):
        """Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–"""
        if self._gemini_client:
            return self._gemini_client
        
        if not self.gemini_api_key:
            print("âš ï¸ GEMINI_API_KEY not set")
            return None
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.gemini_api_key)
            self._gemini_client = genai.GenerativeModel("gemini-1.5-pro")
            return self._gemini_client
        except ImportError:
            print("âš ï¸ google-generativeai not installed")
            print("   pip install google-generativeai")
            return None
    
    def get_gemini_opinion(self, question: str, context: str = "") -> Optional[str]:
        """Gemini ã®æ„è¦‹ã‚’å–å¾—"""
        client = self._init_gemini()
        if not client:
            return None
        
        prompt = f"""ã‚ãªãŸã¯å‰µé€ çš„ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã—ã¦ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§å®Ÿç”¨çš„ãªæ„è¦‹ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚

{f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}" if context else ""}

è³ªå•: {question}

å›ç­”ã¯ç°¡æ½”ã«ã€ç®‡æ¡æ›¸ãã§3-5ç‚¹ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
å¾“æ¥ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚„ã€è¦‹è½ã¨ã•ã‚ŒãŒã¡ãªè¦–ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚
"""
        
        try:
            response = client.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"âš ï¸ Gemini API error: {e}")
            return None
    
    def compare(
        self, 
        question: str,
        claude_opinion: str,
        context: str = ""
    ) -> Dict:
        """
        Claude ã®æ„è¦‹ï¼ˆä¸»ä½“ï¼‰ã¨ Gemini ã®æ„è¦‹ï¼ˆå‚è€ƒï¼‰ã‚’æ¯”è¼ƒ
        
        Args:
            question: è³ªå•
            claude_opinion: Claude ã®æ„è¦‹ï¼ˆäº‹å‰ã«æ±ºå®šæ¸ˆã¿ï¼‰
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            æ¯”è¼ƒçµæœè¾æ›¸
        """
        gemini_opinion = self.get_gemini_opinion(question, context)
        
        result = {
            "question": question,
            "primary": {
                "model": "Claude Opus 4",
                "role": "ä¸»ä½“ï¼ˆå®Ÿè¡Œè²¬ä»»ï¼‰",
                "opinion": claude_opinion
            },
            "reference": {
                "model": "Gemini 1.5 Pro",
                "role": "å‚è€ƒï¼ˆä»£æ›¿è¦–ç‚¹ï¼‰",
                "opinion": gemini_opinion or "ï¼ˆå–å¾—å¤±æ•—ï¼‰"
            }
        }
        
        return result
    
    def format_comparison(self, result: Dict) -> str:
        """æ¯”è¼ƒçµæœã‚’æ•´å½¢ã—ã¦è¡¨ç¤º"""
        output = []
        output.append("=" * 60)
        output.append(f"ğŸ“‹ è³ªå•: {result['question']}")
        output.append("=" * 60)
        output.append("")
        
        # ä¸»ä½“æ„è¦‹ (Claude)
        output.append("â”Œ" + "â”€" * 58 + "â”")
        output.append(f"â”‚ ğŸ¯ {result['primary']['model']} ({result['primary']['role']})")
        output.append("â”œ" + "â”€" * 58 + "â”¤")
        for line in result['primary']['opinion'].split('\n'):
            output.append(f"â”‚ {line}")
        output.append("â””" + "â”€" * 58 + "â”˜")
        output.append("")
        
        # å‚è€ƒæ„è¦‹ (Gemini)
        output.append("â”Œ" + "â”€" * 58 + "â”")
        output.append(f"â”‚ ğŸ’¡ {result['reference']['model']} ({result['reference']['role']})")
        output.append("â”œ" + "â”€" * 58 + "â”¤")
        for line in result['reference']['opinion'].split('\n'):
            output.append(f"â”‚ {line}")
        output.append("â””" + "â”€" * 58 + "â”˜")
        output.append("")
        
        output.append("ğŸ‘¤ ã©ã¡ã‚‰ã‚’æ¡ç”¨ã—ã¾ã™ã‹ï¼Ÿ [A: Claude / B: Gemini / C: çµ±åˆ]")
        
        return "\n".join(output)


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    advisor = MultiModelAdvisor()
    
    # Claude ã®æ„è¦‹ï¼ˆä¸»ä½“ï¼‰
    claude_opinion = """
1. PDFãƒ‘ãƒ©ã‚°ãƒ©ãƒ•æ¤œå‡ºã«ã¯PyMuPDFã®ãƒ–ãƒ­ãƒƒã‚¯â†’ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•è§£æã‚’ä½¿ç”¨
2. ãƒãƒ«ãƒã‚«ãƒ©ãƒ ã¯Xåº§æ¨™ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§æ¤œå‡º
3. OCRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã‚¹ã‚­ãƒ£ãƒ³PDFã«å¯¾å¿œ
4. è¦‹å‡ºã—åˆ¤å®šã¯ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºæ¯”è¼ƒã§å®Ÿè£…
"""
    
    question = "PDF ã‹ã‚‰ã®é•·æ–‡ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•æ¤œå‡ºã«ãŠã„ã¦ã€æœ€é©ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ï¼Ÿ"
    
    result = advisor.compare(question, claude_opinion)
    print(advisor.format_comparison(result))
