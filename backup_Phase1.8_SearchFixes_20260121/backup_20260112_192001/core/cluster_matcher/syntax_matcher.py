"""
SyntaxPatternMatcher - æ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ£ãƒ¼

æ©Ÿèƒ½:
- ãƒ†ã‚­ã‚¹ãƒˆæ§‹é€ ã®èªè­˜ (ã‚³ãƒ”ãƒ¼ã€åå‰ã€ä½æ‰€ã€ä¾¡æ ¼ç­‰)
- æ—¥æœ¬èªç‰¹æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ (ã€’ã€TELã€ç¥ç¤¾ã€é§…ç­‰)
- ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å­¦ç¿’ãƒ»ä¿å­˜
"""

import re
from dataclasses import dataclass, field
from typing import List, Dict, Tuple, Optional, Set
from enum import Enum, auto


class SyntaxType(Enum):
    """æ§‹æ–‡ã‚¿ã‚¤ãƒ—å®šç¾©"""
    UNKNOWN = auto()
    COPY = auto()           # ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼
    GIMMICK = auto()        # ã‚®ãƒŸãƒƒã‚¯æ¥ç¶šè© (ã€œï¼ã€ã€œï¼Ÿãªã©)
    DESCRIPTION = auto()    # èª¬æ˜æ–‡
    NAME = auto()           # äººåãƒ»å›£ä½“å
    PRODUCT = auto()        # å•†å“å
    POSTAL_CODE = auto()    # éƒµä¾¿ç•ªå·
    ADDRESS = auto()        # ä½æ‰€
    PHONE = auto()          # é›»è©±ç•ªå·
    PROPER_NOUN = auto()    # å›ºæœ‰åè©
    PRICE = auto()          # ä¾¡æ ¼
    DECORATIVE = auto()     # é£¾ã‚Šæ–‡å­—ãƒ»è£…é£¾ãƒ†ã‚­ã‚¹ãƒˆ


@dataclass
class SyntaxSignature:
    """æ§‹æ–‡ã‚·ã‚°ãƒãƒãƒ£"""
    detected_types: Set[SyntaxType]
    pattern_scores: Dict[SyntaxType, float]
    dominant_type: SyntaxType
    confidence: float
    
    def similarity(self, other: 'SyntaxSignature') -> float:
        """ä»–ã®ã‚·ã‚°ãƒãƒãƒ£ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        if not self.detected_types and not other.detected_types:
            return 0.0
        
        intersection = self.detected_types & other.detected_types
        union = self.detected_types | other.detected_types
        
        if not union:
            return 0.0
        
        # Jaccardä¿‚æ•°ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦
        jaccard = len(intersection) / len(union)
        
        # æ”¯é…çš„ã‚¿ã‚¤ãƒ—ãŒåŒã˜ãªã‚‰ãƒœãƒ¼ãƒŠã‚¹
        if self.dominant_type == other.dominant_type and self.dominant_type != SyntaxType.UNKNOWN:
            jaccard = min(1.0, jaccard * 1.3)
        
        return jaccard


class SyntaxPatternMatcher:
    """
    æ§‹æ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ£ãƒ¼
    
    æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èªè­˜ã—ã€é¡ä¼¼æ§‹æ–‡ã‚’æŒã¤é ˜åŸŸã‚’ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
    """
    
    # æ‰¿èªæ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
    PATTERNS = {
        SyntaxType.POSTAL_CODE: [
            r'ã€’?\d{3}[-âˆ’]\d{4}',
            r'ã€’\d{7}',
        ],
        SyntaxType.ADDRESS: [
            r'[éƒ½é“åºœçœŒå¸‚åŒºç”ºæ‘].{3,30}[ç•ªåœ°å·]',
            r'[éƒ½é“åºœçœŒ].{2,}[å¸‚åŒºç”ºæ‘].+',
            r'\d+[-âˆ’]\d+[-âˆ’]\d+',
        ],
        SyntaxType.PHONE: [
            r'(TEL|é›»è©±|â˜|ğŸ“)[:ï¼š]?\s*[\d\-()ï¼ˆï¼‰]+',
            r'0\d{1,4}[-âˆ’(]?\d{1,4}[-âˆ’)]?\d{2,4}',
            r'\d{2,4}[-âˆ’]\d{2,4}[-âˆ’]\d{2,4}',
        ],
        SyntaxType.PRICE: [
            r'[Â¥ï¿¥][\d,]+',
            r'[\d,]+å††',
            r'ç¨è¾¼[\d,]+',
            r'[\d,]+ç¨æŠœ',
        ],
        SyntaxType.PROPER_NOUN: [
            r'.*ç¥ç¤¾.*',
            r'.*å¯ºé™¢.*',
            r'.*æ¸©æ³‰.*',
            r'.*é§….*',
            r'.*å…¬åœ’.*',
            r'.*å±±.*',
            r'.*å·.*',
        ],
        SyntaxType.NAME: [
            r'é§…é•·\s*.+',
            r'.+é•·\s*[:ï¼š]?\s*.+',
            r'.+æ°',
            r'.+ã•ã‚“',
            r'.+æ§˜',
        ],
        SyntaxType.PRODUCT: [
            r'.+ã‚»ãƒƒãƒˆ',
            r'.+ãƒ—ãƒ©ãƒ³',
            r'.+ã‚³ãƒ¼ã‚¹',
            r'.+ãƒ‘ãƒƒã‚¯',
            r'ãŠã™ã™ã‚.+',
        ],
        SyntaxType.COPY: [
            r'^.{3,20}[ï¼!]$',
            r'^[ã€Œã€].+[ã€ã€]$',
            r'^.{5,30}$',  # çŸ­ã„ç‹¬ç«‹ãƒ†ã‚­ã‚¹ãƒˆ
        ],
        SyntaxType.GIMMICK: [
            r'.*[ï¼!]{2,}',
            r'.*[ï¼Ÿ?]{2,}',
            r'â˜…+.*',
            r'â—+.*',
            r'â–¶.*',
            r'â—†.*',
        ],
        SyntaxType.DESCRIPTION: [
            r'.{30,}',  # 30æ–‡å­—ä»¥ä¸Šã®èª¬æ˜æ–‡
            r'.+[ã€‚ã€].+[ã€‚ã€].+',  # è¤‡æ•°ã®å¥ç‚¹ã‚’å«ã‚€
        ],
        SyntaxType.DECORATIVE: [
            r'^[â˜†â˜…â—†â—‡â—â—‹â–¶â–·â–ºâ—€â—â—„]+$',
            r'^[â”€â”â•â•Œâ•]+$',
            r'^[â™ªâ™«â™¬â™©]+.*',
            r'^\s*[ãƒ»]+\s*$',
        ],
    }
    
    def __init__(self):
        # æ­£è¦è¡¨ç¾ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        self.compiled_patterns: Dict[SyntaxType, List[re.Pattern]] = {}
        for syntax_type, patterns in self.PATTERNS.items():
            self.compiled_patterns[syntax_type] = [
                re.compile(p, re.UNICODE) for p in patterns
            ]
    
    def extract_syntax_signature(self, text: str) -> SyntaxSignature:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹æ–‡ã‚·ã‚°ãƒãƒãƒ£ã‚’æŠ½å‡º
        
        Args:
            text: åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            SyntaxSignature: æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±
        """
        if not text or not text.strip():
            return SyntaxSignature(
                detected_types=set(),
                pattern_scores={},
                dominant_type=SyntaxType.UNKNOWN,
                confidence=0.0
            )
        
        text = text.strip()
        detected_types: Set[SyntaxType] = set()
        pattern_scores: Dict[SyntaxType, float] = {}
        
        for syntax_type, patterns in self.compiled_patterns.items():
            match_count = 0
            for pattern in patterns:
                if pattern.search(text):
                    match_count += 1
            
            if match_count > 0:
                detected_types.add(syntax_type)
                # ãƒãƒƒãƒã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³æ•°ã«åŸºã¥ãã‚¹ã‚³ã‚¢
                pattern_scores[syntax_type] = min(1.0, match_count * 0.5)
        
        # æ”¯é…çš„ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
        if pattern_scores:
            dominant_type = max(pattern_scores.keys(), key=lambda k: pattern_scores[k])
            confidence = pattern_scores[dominant_type]
        else:
            dominant_type = SyntaxType.UNKNOWN
            confidence = 0.0
        
        return SyntaxSignature(
            detected_types=detected_types,
            pattern_scores=pattern_scores,
            dominant_type=dominant_type,
            confidence=confidence
        )
    
    def calculate_syntax_similarity(
        self, 
        text1: str, 
        text2: str
    ) -> float:
        """
        2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆé–“ã®æ§‹æ–‡é¡ä¼¼åº¦ã‚’è¨ˆç®—
        
        Returns:
            0.0-1.0 ã®é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢
        """
        sig1 = self.extract_syntax_signature(text1)
        sig2 = self.extract_syntax_signature(text2)
        
        return sig1.similarity(sig2)
    
    def find_similar_syntax_clusters(
        self,
        web_regions: List,
        pdf_regions: List,
        threshold: float = 0.5
    ) -> List[Tuple[any, any, float, SyntaxType]]:
        """
        æ§‹æ–‡ãŒé¡ä¼¼ã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒšã‚¢ã‚’ç™ºè¦‹
        
        Args:
            web_regions: Webé ˜åŸŸãƒªã‚¹ãƒˆ
            pdf_regions: PDFé ˜åŸŸãƒªã‚¹ãƒˆ
            threshold: é¡ä¼¼åº¦é–¾å€¤
        
        Returns:
            (web_region, pdf_region, similarity, dominant_type) ã®ãƒªã‚¹ãƒˆ
        """
        matches = []
        
        # å„é ˜åŸŸã®æ§‹æ–‡ã‚·ã‚°ãƒãƒãƒ£ã‚’äº‹å‰è¨ˆç®—
        web_signatures = []
        for r in web_regions:
            text = r.text if hasattr(r, 'text') else r.get('text', '')
            web_signatures.append(self.extract_syntax_signature(text))
        
        pdf_signatures = []
        for r in pdf_regions:
            text = r.text if hasattr(r, 'text') else r.get('text', '')
            pdf_signatures.append(self.extract_syntax_signature(text))
        
        # ãƒãƒƒãƒãƒ³ã‚°
        for i, (wr, ws) in enumerate(zip(web_regions, web_signatures)):
            for j, (pr, ps) in enumerate(zip(pdf_regions, pdf_signatures)):
                sim = ws.similarity(ps)
                
                if sim >= threshold:
                    # æ”¯é…çš„ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
                    if ws.dominant_type == ps.dominant_type:
                        dtype = ws.dominant_type
                    elif ws.confidence > ps.confidence:
                        dtype = ws.dominant_type
                    else:
                        dtype = ps.dominant_type
                    
                    matches.append((wr, pr, sim, dtype))
        
        print(f"[SyntaxMatcher] æ§‹æ–‡é¡ä¼¼ãƒšã‚¢ {len(matches)}ä»¶ã‚’ç™ºè¦‹")
        return matches
    
    def group_by_syntax_type(
        self, 
        regions: List
    ) -> Dict[SyntaxType, List]:
        """
        æ§‹æ–‡ã‚¿ã‚¤ãƒ—ã”ã¨ã«é ˜åŸŸã‚’ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
        
        Args:
            regions: é ˜åŸŸãƒªã‚¹ãƒˆ
        
        Returns:
            {SyntaxType: [é ˜åŸŸãƒªã‚¹ãƒˆ]} ã®è¾æ›¸
        """
        groups: Dict[SyntaxType, List] = {}
        
        for r in regions:
            text = r.text if hasattr(r, 'text') else r.get('text', '')
            sig = self.extract_syntax_signature(text)
            
            if sig.dominant_type not in groups:
                groups[sig.dominant_type] = []
            groups[sig.dominant_type].append(r)
        
        for stype, regs in groups.items():
            print(f"[SyntaxMatcher] {stype.name}: {len(regs)}ä»¶")
        
        return groups
